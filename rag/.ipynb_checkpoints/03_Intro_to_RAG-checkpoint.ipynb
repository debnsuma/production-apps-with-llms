{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG application from scratch using `LangChain` and `Bedrock`\n",
    "\n",
    "Before we get started, I would like to thank to [Santiago](https://www.youtube.com/@underfitted) for his wonderful tutorial on `LangChain`, this notebook is based on his tutorial. \n",
    "Here is a high-level overview of the system we want to build:\n",
    "\n",
    "<img src='./images/IMG_0354.jpg' width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `.env `file in the project directory using env.example as a reference. Populate the .env file with your Aurora PostgreSQL DB cluster details (this we will need later on):\n",
    "\n",
    "```\n",
    "PGVECTOR_DRIVER='psycopg2'\n",
    "PGVECTOR_USER='<<Username>>'\n",
    "PGVECTOR_PASSWORD='<<Password>>'\n",
    "PGVECTOR_HOST='<<Aurora DB cluster host>>'\n",
    "PGVECTOR_PORT=5432\n",
    "PGVECTOR_DATABASE='<<DBName>>'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the `env` variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the environment variables we need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "Let's define the LLM model that we'll use as part of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "model = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model by asking a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The 2019 ICC Cricket World Cup was won by England. It was hosted in England and Wales.\\n\\nIn the final at Lord's Cricket Ground in London, England defeated New Zealand in a dramatic match that went to a Super Over tie-breaker after the scores were tied at the end of the regulation 50 overs per side.\\n\\nEngland scored 241/8 in their 50 overs, which New Zealand also scored to tie the match. In the Super Over, both teams scored 15 runs each. However, England was awarded the World Cup on a controversial boundary countback rule, having scored more boundaries (fours and sixes) during the match.\\n\\nIt was England's first ever Cricket World Cup title. New Zealand were the runners-up for the second consecutive World Cup after 2015. The player of the tournament was Kane Williamson of New Zealand.\", additional_kwargs={'usage': {'prompt_tokens': 20, 'completion_tokens': 189, 'total_tokens': 209}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 20, 'completion_tokens': 189, 'total_tokens': 209}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-eab03c80-107a-4e7b-a695-5e4cc969a529-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Who won the ICC Criket World Cup 2019?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result from the model is an `AIMessage` instance containing the answer. We can extract this answer by chaining the model with an [output parser](https://python.langchain.com/docs/modules/model_io/output_parsers/).\n",
    "\n",
    "Here is what chaining the model with an output parser looks like:\n",
    "\n",
    "<img src='./images/IMG_0355.jpg' width=\"1200\">\n",
    "\n",
    "For this example, we'll use a simple `StrOutputParser` to extract the answer as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 2019 ICC Cricket World Cup was won by England. It was hosted in England and Wales.\\n\\nIn the final at Lord's Cricket Ground in London, England defeated New Zealand in a dramatic match that went to a Super Over tie-breaker after the scores were tied after the regular 50 overs per side.\\n\\nEngland scored 241/8 in their 50 overs, which New Zealand also scored to tie the match. In the Super Over, both teams scored 15 runs each. However, England was awarded the World Cup on a controversial boundary countback rule, having scored more boundaries (fours and sixes) during their innings.\\n\\nIt was England's first ever Cricket World Cup title victory. New Zealand were the runners-up for the second consecutive World Cup after 2015. The player of the tournament was Kane Williamson of New Zealand.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "\n",
    "chain.invoke(\"Who won the ICC Criket World Cup 2019?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing prompt templates\n",
    "\n",
    "We want to provide the model with some context and the question. [Prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/quick_start) are a simple way to define and reuse prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Rashmi is Reyaan's mom\n",
      "\n",
      "Question: Who is Rashmi's son ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "response = prompt.format(context=\"Rashmi is Reyaan's mom\", question=\"Who is Rashmi's son ?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now chain the prompt with the model and the output parser.\n",
    "\n",
    "<img src='./images/IMG_0356.jpg' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context that Rashmi is Reyaan's mom, the answer to \"Who is Rashmi's son?\" is Reyaan.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "response = chain.invoke({\n",
    "                            \"context\": \"Rashmi is Reyaan's mom\",\n",
    "                            \"question\": \"Who is Rashmi's son ?\"\n",
    "                        })\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining chains\n",
    "\n",
    "We can combine different chains to create more complex workflows. For example, let's create a second chain that translates the answer from the first chain into a different language.\n",
    "\n",
    "Let's start by creating a new prompt template for the translation chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "                                                        \"Translate {answer} to {language}\"\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new translation chain that combines the result from the first chain with the translation prompt.\n",
    "\n",
    "Here is what the new workflow looks like:\n",
    "\n",
    "<img src='./images/IMG_0357.jpg' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'दिए गए संदर्भ के आधार पर, जॉन के कुल तीन भाई-बहन हैं: एक भाई माइकल और दो बहनें एलिस और विक्टोरिया।'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain = (\n",
    "                        {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
    "                    )\n",
    "\n",
    "translation_chain.invoke(\n",
    "        {\n",
    "            \"context\": \"John's brother is named Michael. He also has two sisters, Alice and Viktoria.\",\n",
    "            \"question\": \"How many siblings does John have in total?\",\n",
    "            \"language\": \"Hindi\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing the YouTube Video\n",
    "\n",
    "The context we want to send the model comes from a YouTube video. Let's download the video and transcribe it using Amazon Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=lB_0hR5s41Y&ab_channel=BeerBiceps\"\n",
    "S3_BUCKET = 'ml-dl-demo-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription file already exists.\n"
     ]
    }
   ],
   "source": [
    "from utils import transcribe_video\n",
    "\n",
    "transcribe_video(s3_bucket_name=S3_BUCKET, youtube_video_url=YOUTUBE_VIDEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the transcription and display the first few characters to ensure everything works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're a multibillionaire European founder who's moved to Gandhinagar. Yes. Why did you choose Gujar\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"transcription.txt\", \"r\") as file:\n",
    "    transcription = json.loads(file.read())\n",
    "    transcription = transcription['results']['transcripts'][0]['transcript']\n",
    "\n",
    "transcription[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the entire transcription as context\n",
    "\n",
    "If we try to invoke the chain using the transcription as context, the model will return an error because the context is too long.\n",
    "\n",
    "Large Language Models support limitted context sizes. The video we are using is too long for the model to handle, so we need to find a different solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114926"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to Fabian, the most important factor when selecting a location for a business in India is not the location itself, but finding the right person/director to lead the operations there. He says:\\n\\n\"The key to succeed a new company is not the location, the key is the director. This is the most important thing. You can have a good director in a bad location. It will work. You can have a good location, average director, it\\'s gonna be painful.\"\\n\\nHe explains that when expanding to a new location, they first identify the best person/employee within their company who can take the lead, and then open the office wherever that person is based or prefers to be. The location itself is secondary to having the right leadership in place.\\n\\nHe gives examples of opening offices in places like Buffalo, New York and Gandhinagar, Gujarat not because those were targeted locations, but because they had the right people to lead operations there. The focus is on finding talented directors/managers first, and then establishing the business location around them.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"context\": transcription,\n",
    "              \"question\": \"What matters when selecting a location for a business in India ?\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the transcription\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since we can't use the entire transcription as the context for the model, a potential solution is to split the transcription into smaller chunks. We can then invoke the model using only the relevant chunks to answer a particular question:\n",
    "\n",
    "<img src='./images/IMG_0358.jpg' width=\"1200\">\n",
    "\n",
    "Let's start by loading the transcription in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "text_documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to split a document. For this example, we'll use a simple splitter that splits the document into chunks of a fixed size. Check [Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/) for more information about different approaches to splitting documents.\n",
    "\n",
    "For illustration purposes, let's split the transcription into chunks of 100 characters with an overlap of 20 characters and display the first few chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='{\"jobName\":\"Multi-BillionairesJourneyInIndia-LeadershipCultureAndOpportunityOdooTRS386.mp41717446851', metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content='TRS386.mp41717446851\",\"accountId\":\"507922848584\",\"status\":\"COMPLETED\",\"results\":{\"transcripts\":[{\"tr', metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content='{\"transcripts\":[{\"transcript\":\"You\\'re', metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"a multibillionaire European founder who's moved to Gandhinagar. Yes. Why did you choose Gujarat? In\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content='choose Gujarat? In India? We have a ruler to do is we never go to tier one cities. We always go to', metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "text_splitter.split_documents(text_documents)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our specific application, let's use 1000 characters instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the relevant chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given a particular question, we need to find the relevant chunks from the transcription to send to the model. Here is where the idea of **embeddings** comes into play.\n",
    "\n",
    "An embedding is a mathematical representation of the semantic meaning of a word, sentence, or document. It's a projection of a concept in a high-dimensional space. Embeddings have a simple characteristic: The projection of related concepts will be close to each other, while concepts with different meanings will lie far away. \n",
    "\n",
    "To provide with the most relevant chunks, we can use the embeddings of the question and the chunks of the transcription to compute the similarity between them. We can then select the chunks with the highest similarity to the question and use them as the context for the model:\n",
    "\n",
    "<img src='./images/IMG_0359.jpg' width=\"1200\">\n",
    "\n",
    "Let's generate embeddings for an arbitrary query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 1536\n",
      "[1.2890625, 0.4453125, 0.28320312, 0.3984375, 0.050048828, -0.123046875, 0.58984375, -0.0007247925, -0.23535156, 0.48046875]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "embeddings = BedrockEmbeddings()\n",
    "embedded_query = embeddings.embed_query(\"Berlin is in Germany\")\n",
    "\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how embeddings work, let's first generate the embeddings for two different sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = embeddings.embed_query(\"Welcome to Frankfurt\")\n",
    "sentence2 = embeddings.embed_query(\"This is a table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the similarity between the query and each of the two sentences. The closer the embeddings are, the more similar the sentences will be.\n",
    "\n",
    "We can use [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) to calculate the similarity between the query and each of the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6138958023127881, 0.2699050016319834)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "query_sentence1_similarity, query_sentence2_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an efficient way to store document chunks, their embeddings, and perform similarity searches at scale. To do this, we'll use a **vector store**.\n",
    "\n",
    "A vector store is a database of embeddings that specializes in fast similarity searches. \n",
    "\n",
    "<img src='./images/IMG_0360.jpg' width=\"1200\">\n",
    "\n",
    "To understand how a vector store works, let's create one in memory and add a few embeddings to it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing vectors in Amazon Aurora using `pgvector`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; padding: 10px; border-radius: 5px; font-size: 1.1em;\">\n",
    "<b>Prerequisite:</b>\n",
    "<ol>\n",
    "    <li>Have an <b>Aurora cluster ready</b>.</li>\n",
    "    <li>Create the <b>pgvector extension</b> on your Aurora PostgreSQL database (DB) cluster:\n",
    "        <pre style=\"font-size: 1.1em;\"><code>\n",
    "        CREATE EXTENSION vector;\n",
    "        </code></pre>\n",
    "    </li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can connect to the Aurora cluster and check \n",
    "\n",
    "\n",
    "```sql\n",
    "-- SHOW the current database\n",
    "SELECT current_database();\n",
    "\n",
    "-- SHOW all the tables in the database\n",
    "SELECT table_name\n",
    "FROM postgres.information_schema.tables\n",
    "WHERE table_schema = 'public';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainPendingDeprecationWarning: This class is pending deprecation and may be removed in a future version. You can swap to using the `PGVector` implementation in `langchain_postgres`. Please read the guidelines in the doc-string of this class to follow prior to migrating as there are some differences between the implementations. See https://github.com/langchain-ai/langchain-postgres for details aboutthe new implementation.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector, DistanceStrategy\n",
    "\n",
    "# Loading all env variables \n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = 'rag-intro-on-aws'\n",
    "\n",
    "# Connection String\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(driver = os.getenv(\"PGVECTOR_DRIVER\"),\n",
    "                                                              user = os.getenv(\"PGVECTOR_USER\"),                                      \n",
    "                                                              password = os.getenv(\"PGVECTOR_PASSWORD\"),                                  \n",
    "                                                              host = os.getenv(\"PGVECTOR_HOST\"),                                            \n",
    "                                                              port = os.getenv(\"PGVECTOR_PORT\"),                                          \n",
    "                                                              database = os.getenv(\"PGVECTOR_DATABASE\"),\n",
    "                                                              )  \n",
    "\n",
    "# Text Embedding model\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "# Creating the VectorDB store instance   \n",
    "vectorstore1 = PGVector(collection_name=COLLECTION_NAME,\n",
    "                           connection_string=CONNECTION_STRING,\n",
    "                           embedding_function=embeddings,\n",
    "                           distance_strategy = DistanceStrategy.EUCLIDEAN,\n",
    "                           use_jsonb = True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a925f488-3d46-4aea-bee4-d23eb8788d3c',\n",
       " 'f884aa20-5720-4e4b-a51f-e0d79a788e78',\n",
       " '84807713-090e-44e3-9fee-923453cac108',\n",
       " '049d3b43-9c00-4127-bd4f-a83f73351461',\n",
       " '21651cd9-9dac-45fe-ac08-4e08943a05cb',\n",
       " '5e279290-6c6c-473d-a676-3fdd045a46a7',\n",
       " '5c44bcdf-6fdb-4598-b508-4260acd5fdfc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.add_texts([\n",
    "                    \"Color of the bird is red\"\n",
    "                    \"The cat slept by the fire.\",\n",
    "                    \"We went to the park after school.\",\n",
    "                    \"I finished my homework early.\",\n",
    "                    \"The bird sang a beautiful song.\",\n",
    "                    \"She read a book before bed.\",\n",
    "                    \"Mary has two siblings\",\n",
    "                    \"Song was in Spanish\", \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now query the vector store to find the most similar embeddings to a given query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='The bird sang a beautiful song.'),\n",
       "  12.719913663751074),\n",
       " (Document(page_content='The bird sang a beautiful song.'),\n",
       "  12.719913663751074),\n",
       " (Document(page_content='The bird sang a beautiful song.'),\n",
       "  12.719913663751074)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.similarity_search_with_score(query=\"What the bird was singing\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the vector store to the chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the vector store to find the most relevant chunks from the transcription to send to the model. Here is how we can connect the vector store to the chain:\n",
    "\n",
    "<img src='./images/IMG_0361.jpg' width=\"1200\">\n",
    "\n",
    "We need to configure a [Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/). The retriever will run a similarity search in the vector store and return the most similar documents back to the next step in the chain.\n",
    "\n",
    "We can get a retriever directly from the vector store we created before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       " Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       " Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       " Document(page_content='The bird sang a beautiful song.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever1 = vectorstore1.as_retriever()\n",
    "retriever1.invoke(\"Whats the color of the bird who was singing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prompt expects two parameters, \"context\" and \"question.\" We can use the retriever to find the chunks we'll use as the context to answer the question.\n",
    "\n",
    "We can create a map with the two inputs by using the [`RunnableParallel`](https://python.langchain.com/docs/expression_language/how_to/map) and [`RunnablePassthrough`](https://python.langchain.com/docs/expression_language/how_to/passthrough) classes. This will allow us to pass the context and question to the prompt as a map with the keys \"context\" and \"question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       "  Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       "  Document(page_content='Color of the bird is redThe cat slept by the fire.'),\n",
       "  Document(page_content='The bird sang a beautiful song.')],\n",
       " 'question': 'Whats the color of the bird who was singing?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
    "setup.invoke(\"Whats the color of the bird who was singing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add the setup map to the chain and run it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, the color of the bird is red. This is mentioned in the first three documents which state \"Color of the bird is red\".'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | parser\n",
    "chain.invoke(\"Whats the color of the bird who was singing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's invoke the chain using another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the given context, Mary has two siblings. So the answer is yes, Mary has at least one brother or sister.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Does Mary has any brother or sister ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading transcription into the vector store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We initialized the vector store with a few random strings. Let's create a new vector store using the chunks from the video transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Aurora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading all env variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load the text from the file\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "# Set the collection name\n",
    "COLLECTION_NAME = \"rag-intro-yt\"\n",
    "\n",
    "# Connection String\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.getenv(\"PGVECTOR_DRIVER\"),\n",
    "    user=os.getenv(\"PGVECTOR_USER\"),\n",
    "    password=os.getenv(\"PGVECTOR_PASSWORD\"),\n",
    "    host=os.getenv(\"PGVECTOR_HOST\"),\n",
    "    port=os.getenv(\"PGVECTOR_PORT\"),\n",
    "    database=os.getenv(\"PGVECTOR_DATABASE\"),\n",
    ")\n",
    "\n",
    "# Create the PGVector instance from the documents\n",
    "db = PGVector.from_documents(\n",
    "                                embedding=embeddings,\n",
    "                                documents=docs,\n",
    "                                collection_name=COLLECTION_NAME,\n",
    "                                connection_string=CONNECTION_STRING,\n",
    "                                use_jsonb = True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run a similarity search on Aurora to make sure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"that. You like how you're working, right? The reason is that um uh public companies tend to refocus on the short term, you know, you have to uh publish earning codes with the, the sales number and if the numbers are good, everyone is happy, they buy the shares. If numbers are bad, people are not happy and your employees are frustrated because they have shares and it's bad. So public companies have a tendency to focus on the short term to saves, saves of the moments of the quarter and so on. I don't want that the success of FU is always to build for the long term. And I don't want to see on to look for the short term or the sales number of the quarter. One, the other thing is I'm so much focused on productivity and efficiency. Uh When you get public, you need extra layers of reporting transparency, uh anything like that. Uh So second reason I don't want that I want to be super efficient, decide right away instead of asking the board of directors. Um And third, I like open and transparent communication. You know, I just said the company was 4.5 billion of euro. If I was a public company, I could go to jail because I disclosed information uh not be before the earning calls. I think if, if I would have sent that to maybe not publicly but to some I could go to jail. I don't want that. I want to be able to say whatever I want to inform my employees uh and be transparent. Why do you think founders choose to go public? I think a lot of them don't understand, it's just a way to get cash. Um But to understand the consequence of that, most of them don't catch it really another thing. It's bad. I think as a source of cash public is quite good, it's efficient but it comes with some drawbacks like you have to uh have extra layers of reporting complexity. You cannot disclose information and it will refocus the mindset to the short term for some companies. It's good. Some companies need to focus on the short term but it's not us. You know, I would go as far as saying and I might be totally wrong while saying this, but I think there's a bit of a glamour factor also. Yeah, it's a way of being recognized but it's very short term. Like the moment you get public, everyone praise you, you get a lot of praise and then it goes back to reality after deal with the devil. Yeah, you get the same articles that we publish the de because it not big deal. But, um, I'm extreme in everything I do for me. If I lose 1% of productivity, it's bad. I wouldn't want that for do. Um, but, but it's not the devil. It's a, what's the best career advice you ever got in your life from someone? Just do it. That's true because a lot of people a re thinking waiting for the good idea. Um, deciding how we should do it sometime it's just about move on, get the job done first, get the job and maybe it works. Maybe it won't work. But at least you move forward and what's the worst advice you have about advice? I don't know. Um, open uh uh, no, I didn't get bad advice. I didn't follow advice. I don't have mentors and everything. I was working in the other office, which is a farm, in a farm, quite alone, not meeting a lot of people. So I didn't get a lot of feedback. I'm gonna give you a compliment again. Same compliment. You're a crazy guy. Like I have not met anyone like you on the show. No, I think a lot of people who bootstrap do that. You start from where you are and your small things and I don't just mean your professional and even the guy you are, it's very different man. Like, you know, I, I have not seen this on the show and I've spoken to like 600 people, like I've not met someone who's done so much materially, but it's still so humble. Like I still feel you're like a code on the inside. You know, you, that's what I love. I am. A but then that affects a lot of how you look at life. Like someone, not someone else. Many other people in your position would have accomplished what you've accomplished at this point. Either would have chosen to sell it off and just relax or, you know, live more. But then will they be happy by doing that? I think different people have different life stories for me. There is nothing better that I can do than to do. The best I can do is to continue improving the software for companies. It's, I feel like I don't see what I can do better than that, I mean, are you changing as a person as you age? Not as a professional as a human being. Are you changing? I become better. No, I think, no, I become slower because of the age. Um But I think the vision and uh what I wanted to do has always been the same uh not at the very beginning but after a few years it, it has been there. How do you look at Silicon Valley and San Francisco generally? Is it, is it always going to be the center of tech in the world or? Yes, they have a big advance. Um For not for the reason we think the main reason is the cash. They have so many V CS or old ex Google employs with plenty of millions to invest that basically any ID can, can live there and when, when all the ID can leave, some of them will be good and will make a good company. Do you visit? I have an office in San Francisco. Yes. And before office was in uh uh in Silicon Valley and I lived three years there. You lived three years with the family? Yes. Can you talk to me more right now? You're OK to talk to me. Are you getting bored? No, you're enjoying this. I just want to stretch the conversation more. I want to get to know more. Let's go. You don't mind me asking all these questions, right? Like all this time How are you feeling, by the way, in this? Iiiii, I enjoy the, the, the, it's good. We have a good conversation and it's fun because you're getting to think. Uh, yes. And for me it's a different thing that what I used to do. So it's good. Ok. Um, usually people like yourself who come on the show, it's a thought exercise for them because the questions go, like, pretty intense. So, especially entrepreneurs enjoyed being on the show because they get to think much more. They get to reflect. I don't know if you're in that zone. I don't need to think that much because I know my subject. So these things I'm used to talk about. So what value is this conversation adding to you? Not, not, not just you, I'm surprised that you find that the discussion is so good for you that you get a lot of value from it for me just no matter. Ok, but you are adding a lot of value. Like that's why I'm surprised. And it's good to hear. I'm sure this one is going to get international viewers as well because you've not just spoken to the Indian audiences. You know, you've spoken to like, like a lot of people want to expand the businesses in India and they don't know how to my solution to all of them. And I've been asked this question abroad is I think you need to tie up with an Indian partner. Like Indians have the team mentality also like as we value to find. Uh So, I mean, that was my advice until today's podcast. Now, I'll just send them this podcast. Look at this guy's story. Um Maybe before we talk about America, one small question about India for the other foreigner founders, you know, founders from other countries who want to expand in this country. What's your advice to them? I think you just do it. Uh just uh book a flight ticket and come there a few weeks, discuss with people, meet people and in general are very entrepreneurial mindset. So you will find good relationship that you can start using and developing. Just a matter of what I did is that just go to India once you, once you are there, things naturally develop and this whole angle about the population being really big, it's a very legitimate reason to be here, right? Like because the market size is that big and it's growing, it's 8% growth of the GDP per year. It's bigger as in a population that's becoming richer, a big population that's becoming richer. That's the business logic about being here, right? Because at the end of the day, business has to be a little ruthless and mat mathematical. For me, the the initial reason I went to India is but um I was growing very fast in Belgium. Um I was a small company like 20 employees when I went to India and when you grow fast, I was signing project that was um the revenue of the project was bigger than my turnover. The presenting year. So bigger project more than my turnover. But once you do that, you quickly need to recruit and set up the team to deliver the client. And the problem I faced in Belgium. Um If I needed, I had 20 reports. If I needed 20 more, it was like 6 to 9 months to get them, but I just signed a client so I needed it right away. So it's not, it's not so much about the cost of the developers. It was that I needed to uh grow faster. And um and so I had this before because at the end, I wanted to recruit in Belgium. So I recruited Indians so that I have more time to catch up with my, they were sitting in India. Yes. How did you come to know that India has this developer access? Oh Everyone knows that everyone in the tech world knows that. If it was a center of the world, everyone knows that. Like you've heard of invoices and T CS, of course. But have you heard of them before you came to India? And how do you look at invoices and TC si never work with them. So I don't know. But what have you heard it? I mean T CS is 400,000 people. Can you imagine? 400 thousands? It's, it's huge. I saw you reading a book about the Tata group. Yeah, I just thought it page 20 or something. Why are you reading that? I read a lot of books but specifically the Tata Group book you're reading because you're in India. Uh, yes. But I think I would have read it before. No, I just, because it's one of the book I'm reading now. Ok. Coming back to America. Uh, three years in Silicon Valley. You live there? Yes. Uh Tell me everything, man. Like, what was your life like? What were the conversations like? Did you actually get a view of the future? Did you have conversations about A I back then? Which year is this one was seven or eight\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"that. You like how you're working, right? The reason is that um uh public companies tend to refocus on the short term, you know, you have to uh publish earning codes with the, the sales number and if the numbers are good, everyone is happy, they buy the shares. If numbers are bad, people are not happy and your employees are frustrated because they have shares and it's bad. So public companies have a tendency to focus on the short term to saves, saves of the moments of the quarter and so on. I don't want that the success of FU is always to build for the long term. And I don't want to see on to look for the short term or the sales number of the quarter. One, the other thing is I'm so much focused on productivity and efficiency. Uh When you get public, you need extra layers of reporting transparency, uh anything like that. Uh So second reason I don't want that I want to be super efficient, decide right away instead of asking the board of directors. Um And third, I like open and transparent communication. You know, I just said the company was 4.5 billion of euro. If I was a public company, I could go to jail because I disclosed information uh not be before the earning calls. I think if, if I would have sent that to maybe not publicly but to some I could go to jail. I don't want that. I want to be able to say whatever I want to inform my employees uh and be transparent. Why do you think founders choose to go public? I think a lot of them don't understand, it's just a way to get cash. Um But to understand the consequence of that, most of them don't catch it really another thing. It's bad. I think as a source of cash public is quite good, it's efficient but it comes with some drawbacks like you have to uh have extra layers of reporting complexity. You cannot disclose information and it will refocus the mindset to the short term for some companies. It's good. Some companies need to focus on the short term but it's not us. You know, I would go as far as saying and I might be totally wrong while saying this, but I think there's a bit of a glamour factor also. Yeah, it's a way of being recognized but it's very short term. Like the moment you get public, everyone praise you, you get a lot of praise and then it goes back to reality after deal with the devil. Yeah, you get the same articles that we publish the de because it not big deal. But, um, I'm extreme in everything I do for me. If I lose 1% of productivity, it's bad. I wouldn't want that for do. Um, but, but it's not the devil. It's a, what's the best career advice you ever got in your life from someone? Just do it. That's true because a lot of people a re thinking waiting for the good idea. Um, deciding how we should do it sometime it's just about move on, get the job done first, get the job and maybe it works. Maybe it won't work. But at least you move forward and what's the worst advice you have about advice? I don't know. Um, open uh uh, no, I didn't get bad advice. I didn't follow advice. I don't have mentors and everything. I was working in the other office, which is a farm, in a farm, quite alone, not meeting a lot of people. So I didn't get a lot of feedback. I'm gonna give you a compliment again. Same compliment. You're a crazy guy. Like I have not met anyone like you on the show. No, I think a lot of people who bootstrap do that. You start from where you are and your small things and I don't just mean your professional and even the guy you are, it's very different man. Like, you know, I, I have not seen this on the show and I've spoken to like 600 people, like I've not met someone who's done so much materially, but it's still so humble. Like I still feel you're like a code on the inside. You know, you, that's what I love. I am. A but then that affects a lot of how you look at life. Like someone, not someone else. Many other people in your position would have accomplished what you've accomplished at this point. Either would have chosen to sell it off and just relax or, you know, live more. But then will they be happy by doing that? I think different people have different life stories for me. There is nothing better that I can do than to do. The best I can do is to continue improving the software for companies. It's, I feel like I don't see what I can do better than that, I mean, are you changing as a person as you age? Not as a professional as a human being. Are you changing? I become better. No, I think, no, I become slower because of the age. Um But I think the vision and uh what I wanted to do has always been the same uh not at the very beginning but after a few years it, it has been there. How do you look at Silicon Valley and San Francisco generally? Is it, is it always going to be the center of tech in the world or? Yes, they have a big advance. Um For not for the reason we think the main reason is the cash. They have so many V CS or old ex Google employs with plenty of millions to invest that basically any ID can, can live there and when, when all the ID can leave, some of them will be good and will make a good company. Do you visit? I have an office in San Francisco. Yes. And before office was in uh uh in Silicon Valley and I lived three years there. You lived three years with the family? Yes. Can you talk to me more right now? You're OK to talk to me. Are you getting bored? No, you're enjoying this. I just want to stretch the conversation more. I want to get to know more. Let's go. You don't mind me asking all these questions, right? Like all this time How are you feeling, by the way, in this? Iiiii, I enjoy the, the, the, it's good. We have a good conversation and it's fun because you're getting to think. Uh, yes. And for me it's a different thing that what I used to do. So it's good. Ok. Um, usually people like yourself who come on the show, it's a thought exercise for them because the questions go, like, pretty intense. So, especially entrepreneurs enjoyed being on the show because they get to think much more. They get to reflect. I don't know if you're in that zone. I don't need to think that much because I know my subject. So these things I'm used to talk about. So what value is this conversation adding to you? Not, not, not just you, I'm surprised that you find that the discussion is so good for you that you get a lot of value from it for me just no matter. Ok, but you are adding a lot of value. Like that's why I'm surprised. And it's good to hear. I'm sure this one is going to get international viewers as well because you've not just spoken to the Indian audiences. You know, you've spoken to like, like a lot of people want to expand the businesses in India and they don't know how to my solution to all of them. And I've been asked this question abroad is I think you need to tie up with an Indian partner. Like Indians have the team mentality also like as we value to find. Uh So, I mean, that was my advice until today's podcast. Now, I'll just send them this podcast. Look at this guy's story. Um Maybe before we talk about America, one small question about India for the other foreigner founders, you know, founders from other countries who want to expand in this country. What's your advice to them? I think you just do it. Uh just uh book a flight ticket and come there a few weeks, discuss with people, meet people and in general are very entrepreneurial mindset. So you will find good relationship that you can start using and developing. Just a matter of what I did is that just go to India once you, once you are there, things naturally develop and this whole angle about the population being really big, it's a very legitimate reason to be here, right? Like because the market size is that big and it's growing, it's 8% growth of the GDP per year. It's bigger as in a population that's becoming richer, a big population that's becoming richer. That's the business logic about being here, right? Because at the end of the day, business has to be a little ruthless and mat mathematical. For me, the the initial reason I went to India is but um I was growing very fast in Belgium. Um I was a small company like 20 employees when I went to India and when you grow fast, I was signing project that was um the revenue of the project was bigger than my turnover. The presenting year. So bigger project more than my turnover. But once you do that, you quickly need to recruit and set up the team to deliver the client. And the problem I faced in Belgium. Um If I needed, I had 20 reports. If I needed 20 more, it was like 6 to 9 months to get them, but I just signed a client so I needed it right away. So it's not, it's not so much about the cost of the developers. It was that I needed to uh grow faster. And um and so I had this before because at the end, I wanted to recruit in Belgium. So I recruited Indians so that I have more time to catch up with my, they were sitting in India. Yes. How did you come to know that India has this developer access? Oh Everyone knows that everyone in the tech world knows that. If it was a center of the world, everyone knows that. Like you've heard of invoices and T CS, of course. But have you heard of them before you came to India? And how do you look at invoices and TC si never work with them. So I don't know. But what have you heard it? I mean T CS is 400,000 people. Can you imagine? 400 thousands? It's, it's huge. I saw you reading a book about the Tata group. Yeah, I just thought it page 20 or something. Why are you reading that? I read a lot of books but specifically the Tata Group book you're reading because you're in India. Uh, yes. But I think I would have read it before. No, I just, because it's one of the book I'm reading now. Ok. Coming back to America. Uh, three years in Silicon Valley. You live there? Yes. Uh Tell me everything, man. Like, what was your life like? What were the conversations like? Did you actually get a view of the future? Did you have conversations about A I back then? Which year is this one was seven or eight\", metadata={'source': 'transcription.txt'}),\n",
       " Document(page_content=\"that. You like how you're working, right? The reason is that um uh public companies tend to refocus on the short term, you know, you have to uh publish earning codes with the, the sales number and if the numbers are good, everyone is happy, they buy the shares. If numbers are bad, people are not happy and your employees are frustrated because they have shares and it's bad. So public companies have a tendency to focus on the short term to saves, saves of the moments of the quarter and so on. I don't want that the success of FU is always to build for the long term. And I don't want to see on to look for the short term or the sales number of the quarter. One, the other thing is I'm so much focused on productivity and efficiency. Uh When you get public, you need extra layers of reporting transparency, uh anything like that. Uh So second reason I don't want that I want to be super efficient, decide right away instead of asking the board of directors. Um And third, I like open and transparent communication. You know, I just said the company was 4.5 billion of euro. If I was a public company, I could go to jail because I disclosed information uh not be before the earning calls. I think if, if I would have sent that to maybe not publicly but to some I could go to jail. I don't want that. I want to be able to say whatever I want to inform my employees uh and be transparent. Why do you think founders choose to go public? I think a lot of them don't understand, it's just a way to get cash. Um But to understand the consequence of that, most of them don't catch it really another thing. It's bad. I think as a source of cash public is quite good, it's efficient but it comes with some drawbacks like you have to uh have extra layers of reporting complexity. You cannot disclose information and it will refocus the mindset to the short term for some companies. It's good. Some companies need to focus on the short term but it's not us. You know, I would go as far as saying and I might be totally wrong while saying this, but I think there's a bit of a glamour factor also. Yeah, it's a way of being recognized but it's very short term. Like the moment you get public, everyone praise you, you get a lot of praise and then it goes back to reality after deal with the devil. Yeah, you get the same articles that we publish the de because it not big deal. But, um, I'm extreme in everything I do for me. If I lose 1% of productivity, it's bad. I wouldn't want that for do. Um, but, but it's not the devil. It's a, what's the best career advice you ever got in your life from someone? Just do it. That's true because a lot of people a re thinking waiting for the good idea. Um, deciding how we should do it sometime it's just about move on, get the job done first, get the job and maybe it works. Maybe it won't work. But at least you move forward and what's the worst advice you have about advice? I don't know. Um, open uh uh, no, I didn't get bad advice. I didn't follow advice. I don't have mentors and everything. I was working in the other office, which is a farm, in a farm, quite alone, not meeting a lot of people. So I didn't get a lot of feedback. I'm gonna give you a compliment again. Same compliment. You're a crazy guy. Like I have not met anyone like you on the show. No, I think a lot of people who bootstrap do that. You start from where you are and your small things and I don't just mean your professional and even the guy you are, it's very different man. Like, you know, I, I have not seen this on the show and I've spoken to like 600 people, like I've not met someone who's done so much materially, but it's still so humble. Like I still feel you're like a code on the inside. You know, you, that's what I love. I am. A but then that affects a lot of how you look at life. Like someone, not someone else. Many other people in your position would have accomplished what you've accomplished at this point. Either would have chosen to sell it off and just relax or, you know, live more. But then will they be happy by doing that? I think different people have different life stories for me. There is nothing better that I can do than to do. The best I can do is to continue improving the software for companies. It's, I feel like I don't see what I can do better than that, I mean, are you changing as a person as you age? Not as a professional as a human being. Are you changing? I become better. No, I think, no, I become slower because of the age. Um But I think the vision and uh what I wanted to do has always been the same uh not at the very beginning but after a few years it, it has been there. How do you look at Silicon Valley and San Francisco generally? Is it, is it always going to be the center of tech in the world or? Yes, they have a big advance. Um For not for the reason we think the main reason is the cash. They have so many V CS or old ex Google employs with plenty of millions to invest that basically any ID can, can live there and when, when all the ID can leave, some of them will be good and will make a good company. Do you visit? I have an office in San Francisco. Yes. And before office was in uh uh in Silicon Valley and I lived three years there. You lived three years with the family? Yes. Can you talk to me more right now? You're OK to talk to me. Are you getting bored? No, you're enjoying this. I just want to stretch the conversation more. I want to get to know more. Let's go. You don't mind me asking all these questions, right? Like all this time How are you feeling, by the way, in this? Iiiii, I enjoy the, the, the, it's good. We have a good conversation and it's fun because you're getting to think. Uh, yes. And for me it's a different thing that what I used to do. So it's good. Ok. Um, usually people like yourself who come on the show, it's a thought exercise for them because the questions go, like, pretty intense. So, especially entrepreneurs enjoyed being on the show because they get to think much more. They get to reflect. I don't know if you're in that zone. I don't need to think that much because I know my subject. So these things I'm used to talk about. So what value is this conversation adding to you? Not, not, not just you, I'm surprised that you find that the discussion is so good for you that you get a lot of value from it for me just no matter. Ok, but you are adding a lot of value. Like that's why I'm surprised. And it's good to hear. I'm sure this one is going to get international viewers as well because you've not just spoken to the Indian audiences. You know, you've spoken to like, like a lot of people want to expand the businesses in India and they don't know how to my solution to all of them. And I've been asked this question abroad is I think you need to tie up with an Indian partner. Like Indians have the team mentality also like as we value to find. Uh So, I mean, that was my advice until today's podcast. Now, I'll just send them this podcast. Look at this guy's story. Um Maybe before we talk about America, one small question about India for the other foreigner founders, you know, founders from other countries who want to expand in this country. What's your advice to them? I think you just do it. Uh just uh book a flight ticket and come there a few weeks, discuss with people, meet people and in general are very entrepreneurial mindset. So you will find good relationship that you can start using and developing. Just a matter of what I did is that just go to India once you, once you are there, things naturally develop and this whole angle about the population being really big, it's a very legitimate reason to be here, right? Like because the market size is that big and it's growing, it's 8% growth of the GDP per year. It's bigger as in a population that's becoming richer, a big population that's becoming richer. That's the business logic about being here, right? Because at the end of the day, business has to be a little ruthless and mat mathematical. For me, the the initial reason I went to India is but um I was growing very fast in Belgium. Um I was a small company like 20 employees when I went to India and when you grow fast, I was signing project that was um the revenue of the project was bigger than my turnover. The presenting year. So bigger project more than my turnover. But once you do that, you quickly need to recruit and set up the team to deliver the client. And the problem I faced in Belgium. Um If I needed, I had 20 reports. If I needed 20 more, it was like 6 to 9 months to get them, but I just signed a client so I needed it right away. So it's not, it's not so much about the cost of the developers. It was that I needed to uh grow faster. And um and so I had this before because at the end, I wanted to recruit in Belgium. So I recruited Indians so that I have more time to catch up with my, they were sitting in India. Yes. How did you come to know that India has this developer access? Oh Everyone knows that everyone in the tech world knows that. If it was a center of the world, everyone knows that. Like you've heard of invoices and T CS, of course. But have you heard of them before you came to India? And how do you look at invoices and TC si never work with them. So I don't know. But what have you heard it? I mean T CS is 400,000 people. Can you imagine? 400 thousands? It's, it's huge. I saw you reading a book about the Tata group. Yeah, I just thought it page 20 or something. Why are you reading that? I read a lot of books but specifically the Tata Group book you're reading because you're in India. Uh, yes. But I think I would have read it before. No, I just, because it's one of the book I'm reading now. Ok. Coming back to America. Uh, three years in Silicon Valley. You live there? Yes. Uh Tell me everything, man. Like, what was your life like? What were the conversations like? Did you actually get a view of the future? Did you have conversations about A I back then? Which year is this one was seven or eight\", metadata={'source': 'transcription.txt'})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"Can you share the detail of the speaker's journey from starting as a coder to becoming a successful entrepreneur, including the pivot in his business model?\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup the new chain using Aurora as the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": db.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"What are the main challenges and advantages of doing business in India, including insights on market sensitivity, price, and speed of decision-making?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, here are some of the main challenges and advantages of doing business in India mentioned:\n",
      "\n",
      "Challenges:\n",
      "1. The Indian market is very price sensitive. Indian customers focus a lot on getting the cheapest option, sometimes at the expense of quality or efficient service.\n",
      "2. Many Indian companies try to do everything themselves initially instead of buying services, unlike in the US where companies readily buy services.\n",
      "3. There is a mindset of saving money by using more human labor instead of automating processes, even if automation could be more efficient.\n",
      "4. Marketing to Indian businesses has been a challenge since the company was previously known more among developers than businessmen.\n",
      "\n",
      "Advantages: \n",
      "1. India is a fast-deciding market compared to Europe/Africa, with sales cycles being shorter for small companies.\n",
      "2. Indians want to move with speed and go for the cheapest option, which can be advantageous for affordable products/services.\n",
      "3. India has a big growing local market that needs to replace old software with modern solutions.\n",
      "4. Indians are good at negotiation skills, which can be leveraged in business dealings.\n",
      "5. India provides an opportunity with its large population and growth potential, making it an attractive market to invest in compared to other BRIC nations.\n",
      "\n",
      "Other Insights:\n",
      "- Indians are very price-conscious and look to save money, which stems from having a lower level of income/quality of life compared to Americans.\n",
      "- However, this cost-focused mindset sometimes makes Indian companies miss opportunities to improve sales by using better tools, websites, efficient operations etc.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Building a RAG application from scratch using Python - By Santiago](https://www.youtube.com/watch?v=BrsocJb-fAo&t=548s&ab_channel=Underfitted)\n",
    "- [Vector Embeddings and RAG Demystified: Leveraging Amazon Bedrock, Aurora, and LangChain - Part 1](https://community.aws/content/2gvh6fQM4mJQduLye3mHlCNvPxX/vector-embeddings-and-rag-demystified)\n",
    "- [Vector Embeddings and RAG Demystified: Leveraging Amazon Bedrock, Aurora, and LangChain - Part 2](https://community.aws/content/2gvh8oJzNrM4vxdZDd903zcEFJc/vector-embeddings-and-rag-demystified-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“genai”",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
